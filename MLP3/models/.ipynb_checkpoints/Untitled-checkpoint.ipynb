{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befa8c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import pydot\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ctypes\n",
    "import shutil\n",
    "import multiprocessing\n",
    "import multiprocessing.sharedctypes as sharedctypes\n",
    "import os.path\n",
    "import ast\n",
    "\n",
    "\n",
    "# Number of samples per 30s audio clip.\n",
    "# TODO: fix dataset to be constant.\n",
    "NB_AUDIO_SAMPLES = 1321967\n",
    "SAMPLING_RATE = 44100\n",
    "\n",
    "# Load the environment from the .env file.\n",
    "dotenv.load_dotenv(dotenv.find_dotenv())\n",
    "\n",
    "\n",
    "class FreeMusicArchive:\n",
    "\n",
    "    BASE_URL = 'https://freemusicarchive.org/api/get/'\n",
    "\n",
    "    def __init__(self, api_key):\n",
    "        self.api_key = api_key\n",
    "\n",
    "    def get_recent_tracks(self):\n",
    "        URL = 'https://freemusicarchive.org/recent.json'\n",
    "        r = requests.get(URL)\n",
    "        r.raise_for_status()\n",
    "        tracks = []\n",
    "        artists = []\n",
    "        date_created = []\n",
    "        for track in r.json()['aTracks']:\n",
    "            tracks.append(track['track_id'])\n",
    "            artists.append(track['artist_name'])\n",
    "            date_created.append(track['track_date_created'])\n",
    "        return tracks, artists, date_created\n",
    "\n",
    "    def _get_data(self, dataset, fma_id, fields=None):\n",
    "        url = self.BASE_URL + dataset + 's.json?'\n",
    "        url += dataset + '_id=' + str(fma_id) + '&api_key=' + self.api_key\n",
    "        # print(url)\n",
    "        r = requests.get(url)\n",
    "        r.raise_for_status()\n",
    "        if r.json()['errors']:\n",
    "            raise Exception(r.json()['errors'])\n",
    "        data = r.json()['dataset'][0]\n",
    "        r_id = data[dataset + '_id']\n",
    "        if r_id != str(fma_id):\n",
    "            raise Exception('The received id {} does not correspond to'\n",
    "                            'the requested one {}'.format(r_id, fma_id))\n",
    "        if fields is None:\n",
    "            return data\n",
    "        if type(fields) is list:\n",
    "            ret = {}\n",
    "            for field in fields:\n",
    "                ret[field] = data[field]\n",
    "            return ret\n",
    "        else:\n",
    "            return data[fields]\n",
    "\n",
    "    def get_track(self, track_id, fields=None):\n",
    "        return self._get_data('track', track_id, fields)\n",
    "\n",
    "    def get_album(self, album_id, fields=None):\n",
    "        return self._get_data('album', album_id, fields)\n",
    "\n",
    "    def get_artist(self, artist_id, fields=None):\n",
    "        return self._get_data('artist', artist_id, fields)\n",
    "\n",
    "    def get_all(self, dataset, id_range):\n",
    "        index = dataset + '_id'\n",
    "\n",
    "        id_ = 2 if dataset == 'track' else 1\n",
    "        row = self._get_data(dataset, id_)\n",
    "        df = pd.DataFrame(columns=row.keys())\n",
    "        df.set_index(index, inplace=True)\n",
    "\n",
    "        not_found_ids = []\n",
    "\n",
    "        for id_ in id_range:\n",
    "            try:\n",
    "                row = self._get_data(dataset, id_)\n",
    "            except:\n",
    "                not_found_ids.append(id_)\n",
    "                continue\n",
    "            row.pop(index)\n",
    "            df = df.append(pd.Series(row, name=id_))\n",
    "\n",
    "        return df, not_found_ids\n",
    "\n",
    "    def download_track(self, track_file, path):\n",
    "        url = 'https://files.freemusicarchive.org/' + track_file\n",
    "        r = requests.get(url, stream=True)\n",
    "        r.raise_for_status()\n",
    "        with open(path, 'wb') as f:\n",
    "            shutil.copyfileobj(r.raw, f)\n",
    "\n",
    "    def get_track_genres(self, track_id):\n",
    "        genres = self.get_track(track_id, 'track_genres')\n",
    "        genre_ids = []\n",
    "        genre_titles = []\n",
    "        for genre in genres:\n",
    "            genre_ids.append(genre['genre_id'])\n",
    "            genre_titles.append(genre['genre_title'])\n",
    "        return genre_ids, genre_titles\n",
    "\n",
    "    def get_all_genres(self):\n",
    "        df = pd.DataFrame(columns=['genre_parent_id', 'genre_title',\n",
    "                                   'genre_handle', 'genre_color'])\n",
    "        df.index.rename('genre_id', inplace=True)\n",
    "\n",
    "        page = 1\n",
    "        while True:\n",
    "            url = self.BASE_URL + 'genres.json?limit=50'\n",
    "            url += '&page={}&api_key={}'.format(page, self.api_key)\n",
    "            r = requests.get(url)\n",
    "            for genre in r.json()['dataset']:\n",
    "                genre_id = int(genre.pop(df.index.name))\n",
    "                df.loc[genre_id] = genre\n",
    "            assert (r.json()['page'] == str(page))\n",
    "            page += 1\n",
    "            if page > r.json()['total_pages']:\n",
    "                break\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "class Genres:\n",
    "\n",
    "    def __init__(self, genres_df):\n",
    "        self.df = genres_df\n",
    "\n",
    "    def create_tree(self, roots, depth=None):\n",
    "\n",
    "        if type(roots) is not list:\n",
    "            roots = [roots]\n",
    "        graph = pydot.Dot(graph_type='digraph', strict=True)\n",
    "\n",
    "        def create_node(genre_id):\n",
    "            title = self.df.at[genre_id, 'title']\n",
    "            ntracks = self.df.at[genre_id, '#tracks']\n",
    "            # name = self.df.at[genre_id, 'title'] + '\\n' + str(genre_id)\n",
    "            name = '\"{}\\n{} / {}\"'.format(title, genre_id, ntracks)\n",
    "            return pydot.Node(name)\n",
    "\n",
    "        def create_tree(root_id, node_p, depth):\n",
    "            if depth == 0:\n",
    "                return\n",
    "            children = self.df[self.df['parent'] == root_id]\n",
    "            for child in children.iterrows():\n",
    "                genre_id = child[0]\n",
    "                node_c = create_node(genre_id)\n",
    "                graph.add_edge(pydot.Edge(node_p, node_c))\n",
    "                create_tree(genre_id, node_c,\n",
    "                            depth-1 if depth is not None else None)\n",
    "\n",
    "        for root in roots:\n",
    "            node_p = create_node(root)\n",
    "            graph.add_node(node_p)\n",
    "            create_tree(root, node_p, depth)\n",
    "\n",
    "        return graph\n",
    "\n",
    "    def find_roots(self):\n",
    "        roots = []\n",
    "        for gid, row in self.df.iterrows():\n",
    "            parent = row['parent']\n",
    "            title = row['title']\n",
    "            if parent == 0:\n",
    "                roots.append(gid)\n",
    "            elif parent not in self.df.index:\n",
    "                msg = '{} ({}) has parent {} which is missing'.format(\n",
    "                        gid, title, parent)\n",
    "                raise RuntimeError(msg)\n",
    "        return roots\n",
    "\n",
    "\n",
    "def load(filepath):\n",
    "\n",
    "    filename = os.path.basename(filepath)\n",
    "\n",
    "    if 'features' in filename:\n",
    "        return pd.read_csv(filepath, index_col=0, header=[0, 1, 2])\n",
    "\n",
    "    if 'echonest' in filename:\n",
    "        return pd.read_csv(filepath, index_col=0, header=[0, 1, 2])\n",
    "\n",
    "    if 'genres' in filename:\n",
    "        return pd.read_csv(filepath, index_col=0)\n",
    "\n",
    "    if 'tracks' in filename:\n",
    "        tracks = pd.read_csv(filepath, index_col=0, header=[0, 1])\n",
    "\n",
    "        COLUMNS = [('track', 'tags'), ('album', 'tags'), ('artist', 'tags'),\n",
    "                   ('track', 'genres'), ('track', 'genres_all')]\n",
    "        for column in COLUMNS:\n",
    "            tracks[column] = tracks[column].map(ast.literal_eval)\n",
    "\n",
    "        COLUMNS = [('track', 'date_created'), ('track', 'date_recorded'),\n",
    "                   ('album', 'date_created'), ('album', 'date_released'),\n",
    "                   ('artist', 'date_created'), ('artist', 'active_year_begin'),\n",
    "                   ('artist', 'active_year_end')]\n",
    "        for column in COLUMNS:\n",
    "            tracks[column] = pd.to_datetime(tracks[column])\n",
    "\n",
    "        SUBSETS = ('small', 'medium', 'large')\n",
    "        try:\n",
    "            tracks['set', 'subset'] = tracks['set', 'subset'].astype(\n",
    "                    'category', categories=SUBSETS, ordered=True)\n",
    "        except (ValueError, TypeError):\n",
    "            # the categories and ordered arguments were removed in pandas 0.25\n",
    "            tracks['set', 'subset'] = tracks['set', 'subset'].astype(\n",
    "                     pd.CategoricalDtype(categories=SUBSETS, ordered=True))\n",
    "\n",
    "        COLUMNS = [('track', 'genre_top'), ('track', 'license'),\n",
    "                   ('album', 'type'), ('album', 'information'),\n",
    "                   ('artist', 'bio')]\n",
    "        for column in COLUMNS:\n",
    "            tracks[column] = tracks[column].astype('category')\n",
    "\n",
    "        return tracks\n",
    "\n",
    "\n",
    "def get_audio_path(audio_dir, track_id):\n",
    "    \"\"\"\n",
    "    Return the path to the mp3 given the directory where the audio is stored\n",
    "    and the track ID.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> import utils\n",
    "    >>> AUDIO_DIR = os.environ.get('AUDIO_DIR')\n",
    "    >>> utils.get_audio_path(AUDIO_DIR, 2)\n",
    "    '../data/fma_small/000/000002.mp3'\n",
    "\n",
    "    \"\"\"\n",
    "    tid_str = '{:06d}'.format(track_id)\n",
    "    return os.path.join(audio_dir, tid_str[:3], tid_str + '.mp3')\n",
    "\n",
    "\n",
    "class Loader:\n",
    "    def load(self, filepath):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "class RawAudioLoader(Loader):\n",
    "    def __init__(self, sampling_rate=SAMPLING_RATE):\n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.shape = (NB_AUDIO_SAMPLES * sampling_rate // SAMPLING_RATE, )\n",
    "\n",
    "    def load(self, filepath):\n",
    "        return self._load(filepath)[:self.shape[0]]\n",
    "\n",
    "\n",
    "class LibrosaLoader(RawAudioLoader):\n",
    "    def _load(self, filepath):\n",
    "        import librosa\n",
    "        sr = self.sampling_rate if self.sampling_rate != SAMPLING_RATE else None\n",
    "        # kaiser_fast is 3x faster than kaiser_best\n",
    "        # x, sr = librosa.load(filepath, sr=sr, res_type='kaiser_fast')\n",
    "        x, sr = librosa.load(filepath, sr=sr)\n",
    "        return x\n",
    "\n",
    "\n",
    "class AudioreadLoader(RawAudioLoader):\n",
    "    def _load(self, filepath):\n",
    "        import audioread\n",
    "        a = audioread.audio_open(filepath)\n",
    "        a.read_data()\n",
    "\n",
    "\n",
    "class PydubLoader(RawAudioLoader):\n",
    "    def _load(self, filepath):\n",
    "        from pydub import AudioSegment\n",
    "        song = AudioSegment.from_file(filepath)\n",
    "        song = song.set_channels(1)\n",
    "        x = song.get_array_of_samples()\n",
    "        # print(filepath) if song.channels != 2 else None\n",
    "        return np.array(x)\n",
    "\n",
    "\n",
    "class FfmpegLoader(RawAudioLoader):\n",
    "    def _load(self, filepath):\n",
    "        \"\"\"Fastest and less CPU intensive loading method.\"\"\"\n",
    "        import subprocess as sp\n",
    "        command = ['ffmpeg',\n",
    "                   '-i', filepath,\n",
    "                   '-f', 's16le',\n",
    "                   '-acodec', 'pcm_s16le',\n",
    "                   '-ac', '1']  # channels: 2 for stereo, 1 for mono\n",
    "        if self.sampling_rate != SAMPLING_RATE:\n",
    "            command.extend(['-ar', str(self.sampling_rate)])\n",
    "        command.append('-')\n",
    "        # 30s at 44.1 kHz ~= 1.3e6\n",
    "        proc = sp.run(command, stdout=sp.PIPE, bufsize=10**7, stderr=sp.DEVNULL, check=True)\n",
    "\n",
    "        return np.fromstring(proc.stdout, dtype=\"int16\")\n",
    "\n",
    "\n",
    "def build_sample_loader(audio_dir, Y, loader):\n",
    "\n",
    "    class SampleLoader:\n",
    "\n",
    "        def __init__(self, tids, batch_size=4):\n",
    "            self.lock1 = multiprocessing.Lock()\n",
    "            self.lock2 = multiprocessing.Lock()\n",
    "            self.batch_foremost = sharedctypes.RawValue(ctypes.c_int, 0)\n",
    "            self.batch_rearmost = sharedctypes.RawValue(ctypes.c_int, -1)\n",
    "            self.condition = multiprocessing.Condition(lock=self.lock2)\n",
    "\n",
    "            data = sharedctypes.RawArray(ctypes.c_int, tids.data)\n",
    "            self.tids = np.ctypeslib.as_array(data)\n",
    "\n",
    "            self.batch_size = batch_size\n",
    "            self.loader = loader\n",
    "            self.X = np.empty((self.batch_size, *loader.shape))\n",
    "            self.Y = np.empty((self.batch_size, Y.shape[1]), dtype=np.int)\n",
    "\n",
    "        def __iter__(self):\n",
    "            return self\n",
    "\n",
    "        def __next__(self):\n",
    "\n",
    "            with self.lock1:\n",
    "                if self.batch_foremost.value == 0:\n",
    "                    np.random.shuffle(self.tids)\n",
    "\n",
    "                batch_current = self.batch_foremost.value\n",
    "                if self.batch_foremost.value + self.batch_size < self.tids.size:\n",
    "                    batch_size = self.batch_size\n",
    "                    self.batch_foremost.value += self.batch_size\n",
    "                else:\n",
    "                    batch_size = self.tids.size - self.batch_foremost.value\n",
    "                    self.batch_foremost.value = 0\n",
    "\n",
    "                # print(self.tids, self.batch_foremost.value, batch_current, self.tids[batch_current], batch_size)\n",
    "                # print('queue', self.tids[batch_current], batch_size)\n",
    "                tids = np.array(self.tids[batch_current:batch_current+batch_size])\n",
    "\n",
    "            batch_size = 0\n",
    "            for tid in tids:\n",
    "                try:\n",
    "                    audio_path = get_audio_path(audio_dir, tid)\n",
    "                    self.X[batch_size] = self.loader.load(audio_path)\n",
    "                    self.Y[batch_size] = Y.loc[tid]\n",
    "                    batch_size += 1\n",
    "                except Exception as e:\n",
    "                    print(\"\\nIgnoring \" + audio_path +\" (error: \" + str(e) +\").\")\n",
    "\n",
    "            with self.lock2:\n",
    "                while (batch_current - self.batch_rearmost.value) % self.tids.size > self.batch_size:\n",
    "                    # print('wait', indices[0], batch_current, self.batch_rearmost.value)\n",
    "                    self.condition.wait()\n",
    "                self.condition.notify_all()\n",
    "                # print('yield', indices[0], batch_current, self.batch_rearmost.value)\n",
    "                self.batch_rearmost.value = batch_current\n",
    "\n",
    "                return self.X[:batch_size], self.Y[:batch_size]\n",
    "\n",
    "    return SampleLoader\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
